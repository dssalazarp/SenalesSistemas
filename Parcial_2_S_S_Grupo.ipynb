{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dssalazarp/SenalesSistemas/blob/master/Parcial_2_S_S_Grupo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j12WXSQQVoG_"
      },
      "source": [
        "\n",
        "#SOLUCIÓN EXAMEN 2 DE SEÑALES Y SISTEMAS\n",
        "\n",
        "\n",
        "*   Jose Alejandro Velasco Mondragón\n",
        "*   David Santiago Salazar\n",
        "*   Julian David Rivera Prada\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#instalación de librerías\n",
        "!pip install streamlit -q\n",
        "!python3 -m pip install --force-reinstall https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz\n",
        "!pip install soundfile\n",
        "!pip install pydub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryfILSBDh_kh",
        "outputId": "fc0a53f2-b452-4bd6-8b6b-9cd5f6625970"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m920.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz\n",
            "  Downloading https://github.com/yt-dlp/yt-dlp/archive/master.tar.gz\n",
            "\u001b[2K     \u001b[32m-\u001b[0m \u001b[32m2.7 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: yt-dlp\n",
            "  Building wheel for yt-dlp (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yt-dlp: filename=yt_dlp-2025.2.19-py3-none-any.whl size=2947654 sha256=5ec7632f415bf474a1735d7fbfe5113fba2fb18f08231ed598bc522f6ce9a5ad\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-486zfft3/wheels/2d/79/97/7209650ef73114e0fe0603480da012ad3afacb9cae6b8acd9a\n",
            "Successfully built yt-dlp\n",
            "Installing collected packages: yt-dlp\n",
            "Successfully installed yt-dlp-2025.2.19\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.26.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir pages"
      ],
      "metadata": {
        "id": "ABwf_F-1iSCB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 0_👋_PARCIAL.py\n",
        "\n",
        "import streamlit as st\n",
        "\n",
        "st.set_page_config(\n",
        "    page_title=\"Parcial 2\",\n",
        "    page_icon=\"💻\",\n",
        ")\n",
        "\n",
        "st.write(\"# SOLUCIÓN EXAMEN 2 DE SEÑALES Y SISTEMAS  \")\n",
        "\n",
        "st.sidebar.success(\"Seleccione un puntos del parcial.\")\n",
        "\n",
        "st.markdown(\n",
        "    \"\"\"\n",
        "    ### PARCIAL 2 DE SEÑALES Y SISTEMAS\n",
        "\n",
        "\n",
        "*   Jose Alejandro Velasco Mondragón\n",
        "*   David Santiago Salazar\n",
        "*   Julian David Rivera Prada\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QZtBxjElgPA",
        "outputId": "b475643a-05eb-49ad-cbca-8a959b081f9b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing 0_👋_PARCIAL.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PUNTO 1:\n",
        "Encuentre la expresion del espectro de Fourier (forma exponencial y trigonom ´ etrica) para la señal ˜ x(t) = |A cos(2πF ot)|\n",
        "2\n",
        ", con t ∈\n",
        "[−\n",
        "1\n",
        "2Fo\n",
        ",\n",
        "1\n",
        "2Fo\n",
        "], con A, Fo ∈ R\n",
        "+. Realice las simulaciones respectivas para graficar el espectro de Fourier del ejercicio 1 (magnitud\n",
        "y fase como diagrama de Bode en decibelios), y presente el error relativo y la senal reconstruida para ˜ N = {1, 2, . . . , 50}."
      ],
      "metadata": {
        "id": "WZYD4qa8iaNJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pJOOf6nrTHbq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85724ba8-b461-4fdb-fc56-65b227ad2398"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing 1_📈_Punto_1.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile 1_📈_Punto_1.py\n",
        "\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "st.set_page_config(page_title=\"Punto 1\")\n",
        "\n",
        "st.markdown(\"# Punto 1\")\n",
        "st.sidebar.header(\"Control de N\")\n",
        "\n",
        "# Control deslizante para elegir N\n",
        "N = st.sidebar.slider(\"Selecciona el valor de N (número de armónicos)\", min_value=1, max_value=50, value=10)\n",
        "\n",
        "# Parámetros de la señal\n",
        "A = 1\n",
        "Fo = 1\n",
        "T = 1 / Fo\n",
        "t = np.linspace(-T/2, T/2, 1000)\n",
        "\n",
        "# Señal original\n",
        "def x_t(t, A, Fo):\n",
        "    return (A * np.cos(2 * np.pi * Fo * t))**2\n",
        "\n",
        "# Coeficientes de Fourier\n",
        "n_vals = np.arange(-N, N+1)\n",
        "c_n = np.zeros(2*N+1, dtype=complex)\n",
        "\n",
        "for idx, n in enumerate(n_vals):\n",
        "    if n == 0:\n",
        "        c_n[idx] = A**2 / 2\n",
        "    elif abs(n) == 2:\n",
        "        c_n[idx] = A**2 / 4\n",
        "    else:\n",
        "        c_n[idx] = 0\n",
        "\n",
        "# Reconstrucción de la señal\n",
        "x_recon = np.zeros_like(t, dtype=complex)\n",
        "for n, c in zip(n_vals, c_n):\n",
        "    x_recon += c * np.exp(1j * 2 * np.pi * n * Fo * t)\n",
        "x_recon = x_recon.real\n",
        "\n",
        "# Gráfico de la señal original y la reconstruida\n",
        "fig1, ax1 = plt.subplots(figsize=(10, 6))\n",
        "ax1.plot(t, x_t(t, A, Fo), 'k', label=\"Señal original\", linewidth=2)\n",
        "ax1.plot(t, x_recon, 'r--', label=f\"Reconstrucción con N={N}\", linewidth=2)\n",
        "ax1.set_title(\"Reconstrucción de la señal\")\n",
        "ax1.set_xlabel(\"Tiempo (s)\")\n",
        "ax1.set_ylabel(\"Amplitud\")\n",
        "ax1.legend()\n",
        "ax1.grid()\n",
        "st.pyplot(fig1)\n",
        "\n",
        "# Espectro de Fourier (Magnitud y Fase)\n",
        "freqs = n_vals * Fo\n",
        "mag = np.abs(c_n)\n",
        "phase = np.angle(c_n)\n",
        "mag_db = 20 * np.log10(mag + 1e-12)  # Para evitar log(0)\n",
        "\n",
        "fig2, ax2 = plt.subplots(2, 1, figsize=(10, 6))\n",
        "\n",
        "# Magnitud\n",
        "ax2[0].stem(freqs, mag_db)\n",
        "ax2[0].set_ylabel(\"Magnitud (dB)\")\n",
        "ax2[0].set_title(\"Espectro de Fourier\")\n",
        "ax2[0].grid()\n",
        "\n",
        "# Fase\n",
        "ax2[1].stem(freqs, phase)\n",
        "ax2[1].set_ylabel(\"Fase (radianes)\")\n",
        "ax2[1].set_xlabel(\"Frecuencia (Hz)\")\n",
        "ax2[1].grid()\n",
        "\n",
        "st.pyplot(fig2)\n",
        "\n",
        "# Error relativo\n",
        "error = np.linalg.norm(x_recon - x_t(t, A, Fo)) / np.linalg.norm(x_t(t, A, Fo))\n",
        "st.write(f\"**Error relativo:** {error:.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv 1_📈_Punto_1.py pages/"
      ],
      "metadata": {
        "id": "_j_B1MzSiiDi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPuFbuluwHsp"
      },
      "source": [
        "## PUNTO 2\n",
        "\n",
        " Sea la señal portadora $c(t)=A_c\\sin(2\\pi F_c t)$, con $Ac, Fc\\in \\mathbb{R}$, y la señal mensaje $m(t) \\in \\mathbb{R}$. Encuentre el espectro en frecuencia de la señal modulada en amplitud (AM), $y(t)= \\left(1+\\frac{m(t)}{A_c}\\right)c(t)$. Luego, descargue desde youtube 5 segundos de su canción\n",
        "favorita (capturando del segundo 20 al 25). Presente una simulación de modulación por amplitud AM (tomando como mensaje el fragmento de la canción escogida). Grafique las señales en tiempo y frecuencia (magnitud y fase) de la señal mensaje, portadora y modulada. Reproduzca los fragmentos de audio del mensaje, portadora y señal modulada. Nota: se sugiere utilizar un canal de señal de audio para el desarrollo del ejercicio. El usuario debe poder escoger el índice de modulación deseado."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 2_🎧_PUNTO_2.py\n",
        "\n",
        "import streamlit as st\n",
        "import os\n",
        "import yt_dlp as youtube_dl\n",
        "import subprocess\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.fft import rfft, rfftfreq\n",
        "import glob\n",
        "\n",
        "st.set_page_config(page_title=\"PUNTO 2\")\n",
        "\n",
        "st.markdown(\"# 🎧 PUNTO 2.py\")\n",
        "st.sidebar.header(\"PUNTO 2🎧\")\n",
        "st.write(\n",
        "    \"\"\"Sea la señal portadora  c(t)=Acsin(2πFct) , con  Ac,Fc∈R , y la señal mensaje  m(t)∈R .\n",
        "    Encuentre el espectro en frecuencia de la señal modulada en amplitud (AM),  y(t)=(1+m(t)/Ac)c(t) .\n",
        "    Luego, descargue desde youtube 5 segundos de su canción favorita (capturando del segundo 20 al 25).\n",
        "    Presente una simulación de modulación por amplitud AM (tomando como mensaje el fragmento de la canción escogida).\n",
        "    Grafique las señales en tiempo y frecuencia (magnitud y fase) de la señal mensaje, portadora y modulada.\n",
        "    Reproduzca los fragmentos de audio del mensaje, portadora y señal modulada.\n",
        "    Nota: se sugiere utilizar un canal de señal de audio para el desarrollo del ejercicio.\n",
        "    El usuario debe poder escoger el índice de modulación deseado.\"\"\"\n",
        ")\n",
        "\n",
        "# Crear carpeta 'results' si no existe\n",
        "if not os.path.exists(\"results\"):\n",
        "    os.makedirs(\"results\")\n",
        "\n",
        "# Función para limpiar la carpeta 'results'\n",
        "def clear_results_folder():\n",
        "    files = glob.glob('results/*')\n",
        "    for f in files:\n",
        "        os.remove(f)\n",
        "\n",
        "def download_ytvid_as_wav(video_url):\n",
        "    name = \"audio_descargado\"\n",
        "    mp3_filename = f\"results/{name}.mp3\"\n",
        "    wav_filename = f\"results/{name}.wav\"\n",
        "    options = {'format': 'bestaudio/best', 'outtmpl': mp3_filename}\n",
        "    try:\n",
        "        with youtube_dl.YoutubeDL(options) as ydl:\n",
        "            ydl.download([video_url])\n",
        "        subprocess.call(['ffmpeg', '-y', '-i', mp3_filename, wav_filename])\n",
        "        return wav_filename, name\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error al descargar el audio: {e}\")\n",
        "        return None, None\n",
        "\n",
        "video_url = st.text_input(\"### Introduce el URL del video de YouTube:\")\n",
        "\n",
        "if video_url:\n",
        "    clear_results_folder()  # Limpiar archivos previos\n",
        "    wav_filename, name = download_ytvid_as_wav(video_url)\n",
        "    if wav_filename:\n",
        "        st.success(\"Archivo descargado y convertido a WAV.\")\n",
        "        st.audio(wav_filename)\n",
        "\n",
        "        # Extraer fragmento de 5 segundos\n",
        "        fragmento_path = \"results/fragmento.wav\"\n",
        "        subprocess.call(['ffmpeg', '-y', '-i', wav_filename, '-ss', '20', '-t', '5', fragmento_path])\n",
        "        st.success(\"Fragmento extraído correctamente.\")\n",
        "        st.audio(fragmento_path)\n",
        "\n",
        "        # Leer el audio\n",
        "        mensaje, fs = sf.read(fragmento_path)\n",
        "        if len(mensaje.shape) > 1:\n",
        "            mensaje = mensaje.mean(axis=1)\n",
        "        t = np.arange(0, len(mensaje)) / fs\n",
        "\n",
        "        # Parámetros de la portadora\n",
        "        Fc = st.sidebar.slider(\"Frecuencia de la portadora (Hz)\", min_value=500, max_value=15000, value=8000)\n",
        "        Im = st.sidebar.slider(\"Índice de modulación\", min_value=0.1, max_value=1.0, value=0.5)\n",
        "\n",
        "        # Normalizar mensaje\n",
        "        mensaje = mensaje / np.max(np.abs(mensaje))\n",
        "        Ac = max(abs(mensaje))/Im  # Ajuste de amplitud de portadora\n",
        "        portadora = Ac * np.sin(2 * np.pi * Fc * t)\n",
        "        modulado = (1 + mensaje / Ac) * portadora\n",
        "\n",
        "        # Transformada de Fourier\n",
        "        Xfm = rfft(mensaje)\n",
        "        Xfc = rfft(portadora)\n",
        "        Xfy = rfft(modulado)\n",
        "        vfre = rfftfreq(len(mensaje), 1 / fs)\n",
        "\n",
        "        import matplotlib.pyplot as plt\n",
        "        fig, axs = plt.subplots(3, 2, figsize=(12, 8))\n",
        "        axs[0, 0].plot(t, mensaje)\n",
        "        axs[0, 0].set_title(\"Mensaje en el tiempo\")\n",
        "        axs[0, 1].plot(vfre, np.abs(Xfm))\n",
        "        axs[0, 1].set_title(\"Espectro del mensaje\")\n",
        "        axs[1, 0].plot(t, portadora)\n",
        "        axs[1, 0].set_title(\"Portadora en el tiempo\")\n",
        "        axs[1, 1].plot(vfre, np.abs(Xfc))\n",
        "        axs[1, 1].set_title(\"Espectro de la portadora\")\n",
        "        axs[2, 0].plot(t, modulado)\n",
        "        axs[2, 0].set_title(\"Señal modulada en el tiempo\")\n",
        "        axs[2, 1].plot(vfre, np.abs(Xfy))\n",
        "        axs[2, 1].set_title(\"Espectro de la señal modulada\")\n",
        "        plt.tight_layout()\n",
        "        st.pyplot(fig)\n",
        "\n",
        "        # Guardar y reproducir señales\n",
        "        sf.write(\"results/portadora.wav\", portadora, fs)\n",
        "        sf.write(\"results/modulado.wav\", modulado, fs)\n",
        "        st.audio(\"results/portadora.wav\")\n",
        "        st.audio(\"results/modulado.wav\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPY9atxNiszD",
        "outputId": "10ad58be-ccdc-423d-f95c-a98b4312365b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing 2_🎧_PUNTO_2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv 2_🎧_PUNTO_2.py pages/"
      ],
      "metadata": {
        "id": "AX-Fgrctiv5e"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZxFjbhNwKS5"
      },
      "source": [
        "## PUNTO 3\n",
        "Consulte en que consiste la distorsión total de armónicos (Total Harmonic Distortion-(THD)) y el factor de potencia en un circuito electrico. ¿Cómo puede calcularse el THD desde la FFT?. Cómo puede calcularse la distorsión del factor de potencia con base al THD?. Genere un ejemplo ilustrativo para el calculo del THD y la distorsión del factor de potencia para un rectificador de onda completa con carga: i) netamente resistiva y ii) carga RC en serie. Establezca las condiciones necesarias para las simulaciones. El\n",
        "usuario podra escoger diferentes valores de R y C. Discuta los resultados obtenidos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t71kJzOfOds-"
      },
      "source": [
        "CONSULTA DE LA DISTORSION TOTAL DE ARMONICOS:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idalP-9EQzaQ"
      },
      "source": [
        "¿En qué consiste la distorsión total de armónicos y el factor de potencia de un circuito? (THD)\n",
        "\n",
        "La distorsión total de armónicos es definida como la cuantificación de qué tanto se distrosiónan los armónicos presentes en una señal. De esa manera, las deformaciones presentes en la gráfica con respecto al tiempo de señales de tensión y corriente (para el caso particular del sistema eléctrico) representan la distorsión de armónicos que suele ser causada por diferentes fenómenos como:\n",
        "- Transitorios\n",
        "- Operación en estado estable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uCAveXTQ5WQ"
      },
      "source": [
        "¿Cómo puede calcularse la distorsión del factor de potencia con base al THD?\n",
        "Al tratar el tema de armónicos, THD y factor de potencia, se plantea una relación natural e intrínseca entre los conceptos antes mencionados. La distorsión armónica total se puede definir como la manera en la que la cantidad de distorsión generada por frecuencias armónicas afecta un sistema eléctrico. De la teoría de circuitos, se define el factor de potencia como la medida de eficiencia que alcanza un circuito en términos de conversión de energía en energía útil. Por las definiciones presentadas anteriormente, es posible encontrar la relación entre los conceptos de THD y de factor de potencia poniendo todo el análisis en términos de la eficiencia del sistema.\n",
        "\n",
        "Así, de manera matemática, la expresión que relaciona el factor de potencia con el THD es la siguiente:\n",
        "\n",
        "$$ PF_{THD} = \\sqrt{\\frac{1}{1 + (THD)^2}} $$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 3_📉_PUNTO_3.py\n",
        "\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import scipy.signal as sig\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "st.set_page_config(page_title=\"PUNTO 3\", page_icon=\"📉\")\n",
        "\n",
        "st.markdown(\"# PUNTO 3\")\n",
        "st.sidebar.header(\"PUNTO 3\")\n",
        "st.write(\n",
        "    \"\"\"Consulte en qué consiste la distorsión total de armónicos (Total Harmonic Distortion-(THD)) y el factor de potencia en un circuito eléctrico...\"\"\"\n",
        ")\n",
        "\n",
        "# Parámetros de entrada\n",
        "R = st.sidebar.number_input(\"Ingrese el valor de la resistencia (Ω):\", min_value=0.0, value=100.0, step=1.0)\n",
        "C = st.sidebar.number_input(\n",
        "    \"Ingrese el valor de la capacitancia (F, 0 para circuito R):\",\n",
        "    min_value=0.0,\n",
        "    value=0.0,\n",
        "    step=0.000001,\n",
        "    format=\"%.6f\"\n",
        ")\n",
        "\n",
        "def simulate_circuit(R, C):\n",
        "    A = 120\n",
        "    Fo = 60\n",
        "    Fs = 100 * Fo  # Mayor resolución en la FFT\n",
        "    To = 1 / Fo\n",
        "    Ts = 1 / Fs\n",
        "    t = np.arange(0, 10 * To, Ts)  # 10 periodos para mayor precisión\n",
        "\n",
        "    in_o = A * np.sin(2 * np.pi * Fo * t)\n",
        "    in_ = np.abs(in_o)\n",
        "\n",
        "    if C > 0:\n",
        "        num = np.array([1])\n",
        "        den = np.array([R * C, 1])\n",
        "        G_n = sig.TransferFunction(num, den)\n",
        "        _, out_signal, _ = sig.lsim(G_n, in_, t)\n",
        "    else:\n",
        "        out_signal = in_\n",
        "\n",
        "    fig, axs = plt.subplots(3, 1, figsize=(10, 6))\n",
        "    axs[0].plot(t, in_o)\n",
        "    axs[0].set_title(\"Señal de Alimentación\")\n",
        "    axs[1].plot(t, in_)\n",
        "    axs[1].set_title(\"Señal Rectificada\")\n",
        "    axs[2].plot(t, out_signal)\n",
        "    axs[2].set_title(\"Señal de Salida\")\n",
        "    for ax in axs:\n",
        "        ax.set_xlabel(\"Tiempo (s)\")\n",
        "        ax.set_ylabel(\"Amplitud (V)\")\n",
        "    plt.tight_layout()\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    N = len(out_signal)\n",
        "    Xf = np.fft.fft(out_signal)\n",
        "    Xf_mag = 2.0 / N * np.abs(Xf[:N // 2])\n",
        "    freqs = np.fft.fftfreq(N, Ts)[:N // 2]\n",
        "\n",
        "    fig, axs = plt.subplots(2, 1, figsize=(10, 6))\n",
        "    axs[0].stem(freqs, 20 * np.log10(Xf_mag), basefmt=\" \")\n",
        "    axs[0].set_title(\"Espectro de Fourier (Magnitud)\")\n",
        "    axs[0].set_ylabel(\"Magnitud (dB)\")\n",
        "    axs[1].stem(freqs, np.angle(Xf[:N // 2]), basefmt=\" \")\n",
        "    axs[1].set_xlabel(\"Frecuencia (Hz)\")\n",
        "    axs[1].set_ylabel(\"Fase (radianes)\")\n",
        "    plt.tight_layout()\n",
        "    st.pyplot(fig)\n",
        "\n",
        "    def calculate_thd(signal, Fs):\n",
        "        N = len(signal)\n",
        "        Y = np.fft.fft(signal)\n",
        "        freqs = np.fft.fftfreq(N, 1 / Fs)\n",
        "        Y_mag = 2.0 / N * np.abs(Y)\n",
        "\n",
        "        # Buscar el pico máximo para la frecuencia fundamental\n",
        "        positive_freqs = freqs[:N // 2]\n",
        "        positive_mags = Y_mag[:N // 2]\n",
        "        fundamental_idx = np.argmax(positive_mags)\n",
        "        fundamental = positive_mags[fundamental_idx]\n",
        "\n",
        "        # Armónicos (excluyendo la fundamental)\n",
        "        harmonics = np.sqrt(np.sum(positive_mags[fundamental_idx + 1:] ** 2))\n",
        "        return harmonics / fundamental if fundamental != 0 else float('inf')\n",
        "\n",
        "    THD = calculate_thd(out_signal, Fs)\n",
        "    st.write(f\"**THD (Distorsión Armónica Total):** {THD:.2%}\")\n",
        "\n",
        "    def calculate_power_factor(THD):\n",
        "        return np.sqrt(1 / (1 + THD ** 2))\n",
        "\n",
        "    FP = calculate_power_factor(THD)\n",
        "    st.write(f\"**Factor de Potencia:** {FP:.2f}\")\n",
        "\n",
        "if st.button(\"Ejecutar Simulación\"):\n",
        "    simulate_circuit(R, C)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9UAAPbLe16U",
        "outputId": "526a0bdc-37ca-4bc9-8518-2cccfc4e98f9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing 3_📉_PUNTO_3.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv 3_📉_PUNTO_3.py pages/"
      ],
      "metadata": {
        "id": "xWLg29d-i3s-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8WJCYmLwLlj"
      },
      "source": [
        "## PUNTO 4\n",
        "Desarrolle un sistema para identificar una palabra clave y autenticar al hablante utilizando herramientas basadas en la Transformada\n",
        "de Fourier. El sistema debe presentarse como un Dashboard en Streamlit y cumplir con las siguientes condiciones: i) Permitir el\n",
        "acceso unicamente si un miembro del grupo pronuncia la palabra clave. ii) Denegar el acceso en cualquier otro caso. ´\n",
        "Ademas, se debe presentar y describir el esquema de soluci ´ on que incluya: i) Dise ´ no del sistema de detecci ˜ on. ii) La base de ´\n",
        "datos creada para almacenar los patrones de voz y palabras clave. iii) Las consideraciones tecnicas para implementar la soluci ´ on, ´\n",
        "incluyendo el uso de la Transformada de Fourier para procesar las senales de voz."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 4_⚔️_PUNTO_4.py\n",
        "\n",
        "\n",
        "import librosa.display\n",
        "import os\n",
        "import pandas as pd\n",
        "import gdown\n",
        "import requests\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import streamlit as st\n",
        "import matplotlib.pyplot as plt\n",
        "from io import BytesIO\n",
        "from pydub import AudioSegment, silence\n",
        "from scipy.fft import rfft, fftfreq\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from scipy.spatial.distance import euclidean\n",
        "\n",
        "st.set_page_config(page_title=\"Autenticación por Voz\", page_icon=\"🔊\")\n",
        "st.markdown(\"# Autenticación por Voz\")\n",
        "st.sidebar.header(\"Parámetros del Sistema\")\n",
        "st.write(\"Sistema para identificar una palabra clave y autenticar al hablante utilizando herramientas basadas en la Transformada de Fourier.\")\n",
        "\n",
        "# Función para convertir enlaces de Google Drive\n",
        "def convertir_link_google_drive(url):\n",
        "    if \"drive.google.com\" in url and \"/file/d/\" in url:\n",
        "        file_id = url.split(\"/d/\")[1].split(\"/\")[0]\n",
        "        return f\"https://drive.google.com/uc?id={file_id}\"\n",
        "    return url\n",
        "\n",
        "# Función para obtener enlace de descarga de Google Sheets\n",
        "def descargar_csv_google_sheets(sheet_url):\n",
        "    file_id = sheet_url.split(\"/d/\")[1].split(\"/\")[0]\n",
        "    return f\"https://docs.google.com/spreadsheets/d/{file_id}/export?format=csv\"\n",
        "st.write(\"url base de datos: https://docs.google.com/spreadsheets/d/1gwLO2NXxBKnM2urol12aTqn9_HOhT-q1/edit?usp=sharing&ouid=115292432287984287407&rtpof=true&sd=true.\")\n",
        "\n",
        "# Carga de base de datos\n",
        "sheet_url = st.text_input(\"Ingrese el enlace de Google Sheets:\", \"\")\n",
        "if sheet_url:\n",
        "    download_url = descargar_csv_google_sheets(sheet_url)\n",
        "    df = pd.read_csv(BytesIO(requests.get(download_url).content))\n",
        "    st.write(\"Base de datos cargada con éxito ✅\")\n",
        "    st.dataframe(df.head())\n",
        "\n",
        "# Crear carpetas si no existen\n",
        "os.makedirs(\"audios_originales\", exist_ok=True)\n",
        "os.makedirs(\"audios_segmentados\", exist_ok=True)\n",
        "\n",
        "# Procesamiento de audios\n",
        "def procesar_audios():\n",
        "    for index, row in df.iterrows():\n",
        "        audio_url = convertir_link_google_drive(row[\"link\"])\n",
        "        user, tipo, identificador = row[\"usuario\"], row[\"type\"], row[\"type_num\"]\n",
        "        input_file = f\"audios_originales/{user}{tipo}{identificador}.wav\"\n",
        "\n",
        "        if not os.path.exists(input_file):\n",
        "            gdown.download(audio_url, input_file, quiet=False)\n",
        "\n",
        "        try:\n",
        "            audio = AudioSegment.from_file(input_file)\n",
        "            audio.export(input_file, format=\"wav\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error al procesar {input_file}: {e}\")\n",
        "            continue\n",
        "\n",
        "        audio = AudioSegment.from_wav(input_file)\n",
        "        segmentos = silence.split_on_silence(audio, min_silence_len=200, silence_thresh=audio.dBFS - 30, keep_silence=100)\n",
        "\n",
        "        for i, segmento in enumerate(segmentos):\n",
        "            output_file = f\"audios_segmentados/{user}{tipo}{identificador}_segmento{i}.wav\"\n",
        "            segmento.export(output_file, format=\"wav\")\n",
        "        st.write(f\"{len(segmentos)} fragmentos guardados para {input_file}.\")\n",
        "\n",
        "if st.button(\"Procesar Audios\"):\n",
        "    procesar_audios()\n",
        "    st.success(\"Proceso de descarga y segmentación finalizado ✅\")\n",
        "\n",
        "# Subir archivo de audio\n",
        "uploaded_file = st.file_uploader(\"Sube un audio para verificar:\", type=[\"wav\"])\n",
        "if uploaded_file:\n",
        "    audio = AudioSegment.from_file(uploaded_file)\n",
        "    segmentos = silence.split_on_silence(audio, min_silence_len=200, silence_thresh=audio.dBFS - 30, keep_silence=100)\n",
        "\n",
        "    if segmentos:\n",
        "        recortado = sum(segmentos)\n",
        "        recortado.export(\"audio_recortado.wav\", format=\"wav\")\n",
        "        st.audio(\"audio_recortado.wav\", format=\"audio/wav\")\n",
        "\n",
        "        # Procesar audios segmentados\n",
        "        wav_files = [f for f in os.listdir(\"audios_segmentados\") if f.endswith(\".wav\")]\n",
        "        x_t, labels, names = [], [], []\n",
        "        ts, fs = 2, 48000\n",
        "        target_length = ts * fs\n",
        "\n",
        "        for name in wav_files:\n",
        "            try:\n",
        "                x, fs = sf.read(os.path.join(\"audios_segmentados\", name))\n",
        "                if x.ndim > 1:\n",
        "                    x = x.mean(axis=1)\n",
        "                x = np.pad(x, (0, max(0, target_length - len(x))), 'constant')[:target_length]\n",
        "                x_t.append(x)\n",
        "                labels.append(1 if any(kw in name for kw in [\"santiago\", \"alejandro\", \"julian\"]) and \"clave\" in name else 0)\n",
        "                names.append(name)\n",
        "            except Exception as e:\n",
        "                st.error(f\"Error al leer {name}: {e}\")\n",
        "                continue\n",
        "\n",
        "        x_t = np.array(x_t)\n",
        "        Xw = rfft(x_t, axis=1)\n",
        "        scaler = MinMaxScaler()\n",
        "        Xw_abs = np.abs(Xw)\n",
        "        Xw_norm = scaler.fit_transform(Xw_abs)\n",
        "\n",
        "        # Procesar el nuevo audio\n",
        "        x_new, sr = sf.read(\"audio_recortado.wav\")\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        librosa.display.waveshow(x_new, sr=sr)\n",
        "        plt.title(\"Audio Recortado\")\n",
        "        st.pyplot(plt)\n",
        "\n",
        "        if x_new.ndim > 1:\n",
        "            x_new = x_new.mean(axis=1)\n",
        "        x_new = np.pad(x_new, (0, max(0, target_length - len(x_new))), 'constant')[:target_length]\n",
        "\n",
        "        Xw_new = rfft(x_new)\n",
        "        Xw_new_abs = np.abs(Xw_new).reshape(1, -1)\n",
        "        Xw_new_norm = scaler.transform(Xw_new_abs).flatten()\n",
        "\n",
        "        # Calcular distancias euclidianas\n",
        "        distances = [euclidean(Xw_new_norm, x_db) for x_db in Xw_norm]\n",
        "        min_dist = min(distances)\n",
        "        threshold = np.percentile(distances, 10)\n",
        "\n",
        "        st.write(f\"Distancia mínima: {min_dist}\")\n",
        "        st.write(f\"Umbral de autenticación: {threshold}\")\n",
        "\n",
        "        if min_dist < threshold:\n",
        "            st.success(\"¡Usuario autenticado correctamente! ✅\")\n",
        "        else:\n",
        "            st.error(\"❌ Acceso denegado. No coincide con la base de datos.\")\n",
        "\n",
        "        # Visualización con t-SNE\n",
        "        tsne = TSNE(n_components=2, perplexity=10, random_state=42)\n",
        "        X_embedded = tsne.fit_transform(np.vstack([Xw_norm, Xw_new_norm.reshape(1, -1)]))\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.scatter(X_embedded[:-1, 0], X_embedded[:-1, 1], c=labels, cmap='bwr', alpha=0.5, label='Base de datos')\n",
        "        ax.scatter(X_embedded[-1, 0], X_embedded[-1, 1], color='yellow', label='Audio Nuevo', edgecolors='black')\n",
        "        ax.set_xlabel(\"Dimensión 1\")\n",
        "        ax.set_ylabel(\"Dimensión 2\")\n",
        "        ax.legend()\n",
        "        ax.set_title(\"Visualización de Embeddings con t-SNE\")\n",
        "        st.pyplot(fig)\n",
        "\n",
        "        # Graficar espectro en frecuencia\n",
        "        fig, ax = plt.subplots(figsize=(10, 5))\n",
        "        freqs = fftfreq(len(Xw_new), 1/fs)[:len(Xw_new)//2]\n",
        "        ax.plot(freqs, np.abs(Xw_new[:len(freqs)]), label=\"Audio Nuevo\", color=\"gold\")\n",
        "\n",
        "        for i, Xw_i in enumerate(Xw[:10]):\n",
        "            ax.plot(freqs, np.abs(Xw_i[:len(freqs)]), alpha=0.5, label=f\"Base {i+1}\")\n",
        "\n",
        "        ax.set_xlabel(\"Frecuencia (Hz)\")\n",
        "        ax.set_ylabel(\"Magnitud\")\n",
        "        ax.set_title(\"Comparación de Espectros en Frecuencia\")\n",
        "        ax.legend()\n",
        "        st.pyplot(fig)\n",
        "\n",
        "    else:\n",
        "        st.error(\"No se detectó una palabra clave en el audio.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROPKqflgi9BB",
        "outputId": "7a04fa1a-0c43-4ae8-fe15-6d7339e7a52c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing 4_⚔️_PUNTO_4.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv 4_⚔️_PUNTO_4.py pages/"
      ],
      "metadata": {
        "id": "JcT8aR42aGZx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inicialización del Dashboard a partir de túnel local**"
      ],
      "metadata": {
        "id": "Git3P-92jpy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!chmod +x cloudflared-linux-amd64\n",
        "!mv cloudflared-linux-amd64 /usr/local/bin/cloudflared\n",
        "\n",
        "#Ejecutar Streamlit\n",
        "!streamlit run 0_👋_PARCIAL.py &>/content/logs.txt & #Cambiar 0_👋_Hello.py por el nombre de tu archivo principal\n",
        "\n",
        "#Exponer el puerto 8501 con Cloudflare Tunnel\n",
        "!cloudflared tunnel --url http://localhost:8501 > /content/cloudflared.log 2>&1 &\n",
        "\n",
        "#Leer la URL pública generada por Cloudflare\n",
        "import time\n",
        "time.sleep(5)  # Esperar que se genere la URL\n",
        "\n",
        "import re\n",
        "found_context = False  # Indicador para saber si estamos en la sección correcta\n",
        "\n",
        "with open('/content/cloudflared.log') as f:\n",
        "    for line in f:\n",
        "        #Detecta el inicio del contexto que nos interesa\n",
        "        if \"Your quick Tunnel has been created\" in line:\n",
        "            found_context = True\n",
        "\n",
        "        #Busca una URL si ya se encontró el contexto relevante\n",
        "        if found_context:\n",
        "            match = re.search(r'https?://\\S+', line)\n",
        "            if match:\n",
        "                url = match.group(0)  #Extrae la URL encontrada\n",
        "                print(f'Tu aplicación está disponible en: {url}')\n",
        "                break  #Termina el bucle después de encontrar la URL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PChwaZsjE2p",
        "outputId": "5ff8f0a3-590e-46e7-d8b2-9810fedd6f64"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-05 14:16:59--  https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/cloudflare/cloudflared/releases/download/2025.2.1/cloudflared-linux-amd64 [following]\n",
            "--2025-03-05 14:16:59--  https://github.com/cloudflare/cloudflared/releases/download/2025.2.1/cloudflared-linux-amd64\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/eac8237f-c554-46b5-95ea-f2f5873e69a5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250305%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250305T141659Z&X-Amz-Expires=300&X-Amz-Signature=9165fd025692c19d54612cbd9ece5057c5dd3fa961a5526c6078db1452beac6d&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-03-05 14:16:59--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/eac8237f-c554-46b5-95ea-f2f5873e69a5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250305%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250305T141659Z&X-Amz-Expires=300&X-Amz-Signature=9165fd025692c19d54612cbd9ece5057c5dd3fa961a5526c6078db1452beac6d&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 37844205 (36M) [application/octet-stream]\n",
            "Saving to: ‘cloudflared-linux-amd64’\n",
            "\n",
            "cloudflared-linux-a 100%[===================>]  36.09M  71.0MB/s    in 0.5s    \n",
            "\n",
            "2025-03-05 14:17:00 (71.0 MB/s) - ‘cloudflared-linux-amd64’ saved [37844205/37844205]\n",
            "\n",
            "Tu aplicación está disponible en: https://cameroon-compilation-dawn-carey.trycloudflare.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Finalización de ejecución del Dashboard**"
      ],
      "metadata": {
        "id": "gVlw-jygjOFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "res = input(\"Digite (1) para finalizar la ejecución del Dashboard: \")\n",
        "\n",
        "if res.upper() == \"1\":\n",
        "    os.system(\"pkill streamlit\")  # Termina el proceso de Streamlit\n",
        "    print(\"El proceso de Streamlit ha sido finalizado.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYduqMcUjIBx",
        "outputId": "84094387-6d45-4888-ec15-dcf83ee2da83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Digite (1) para finalizar la ejecución del Dashboard: 1\n",
            "El proceso de Streamlit ha sido finalizado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nICwhrhUhYe_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}